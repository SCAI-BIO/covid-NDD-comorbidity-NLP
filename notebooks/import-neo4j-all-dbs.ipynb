{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import requests\r\n",
    "import json\r\n",
    "import time\r\n",
    "import urllib3\r\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\r\n",
    "import pandas as pd\r\n",
    "from py2neo import Graph, Node, Relationship\r\n",
    "import math\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###DISGENET######\r\n",
    "# Insert graph to Neo4j\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import math\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "# Neo4j connection details\r\n",
    "uri = \"bolt://localhost:7687\"\r\n",
    "user = \"neo4j\"\r\n",
    "password = \"12345678\"\r\n",
    "graph = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "\r\n",
    "def merge_node_disease(label, disease_name, disease_id, source):\r\n",
    "    merge_query = f\"\"\"\r\n",
    "    MERGE (n:{label} {{name: $name, id: $id}})\r\n",
    "    ON CREATE SET n.source = $source\r\n",
    "    RETURN n\r\n",
    "    \"\"\"\r\n",
    "    with graph.session() as session:\r\n",
    "        return session.run(merge_query, name=disease_name, id=disease_id, source=source).single()\r\n",
    "\r\n",
    "def merge_node_gene(label, gene_symbol, gene_ens_id, source):\r\n",
    "    merge_query = f\"\"\"\r\n",
    "    MERGE (n:{label} {{symbol: $symbol, id: $id}})\r\n",
    "    ON CREATE SET n.source = $source\r\n",
    "    RETURN n\r\n",
    "    \"\"\"\r\n",
    "    with graph.session() as session:\r\n",
    "        return session.run(merge_query, symbol=gene_symbol, id=gene_ens_id, source=source).single()\r\n",
    "\r\n",
    "def merge_relationship(disease_id, gene_id, association_type, pmid, source, score):\r\n",
    "    properties = []\r\n",
    "    params = {'disease_id': disease_id, 'gene_id': gene_id}\r\n",
    "\r\n",
    "    if pmid is not None:\r\n",
    "        properties.append(\"pmid: $pmid\")\r\n",
    "        params['pmid'] = pmid\r\n",
    "    if source is not None:\r\n",
    "        properties.append(\"source: $source\")\r\n",
    "        params['source'] = source\r\n",
    "    if score is not None:\r\n",
    "        properties.append(\"score: $score\")\r\n",
    "        params['score'] = score\r\n",
    "\r\n",
    "    properties_str = \", \".join(properties)\r\n",
    "\r\n",
    "    relationship_query = f\"\"\"\r\n",
    "    MATCH (d:Disease {{id: $disease_id}})\r\n",
    "    MATCH (g:Gene {{id: $gene_id}})\r\n",
    "    MERGE (d)-[r:{association_type} {{{properties_str}}}]->(g)\r\n",
    "    RETURN r\r\n",
    "    \"\"\"\r\n",
    "    with graph.session() as session:\r\n",
    "        return session.run(relationship_query, **params).single()\r\n",
    "\r\n",
    "# Read CSV file\r\n",
    "directory = \"data/DISGENET/api-call-results\"\r\n",
    "for filename in os.listdir(directory):\r\n",
    "    if filename.endswith(\".csv\"):\r\n",
    "        # Load the CSV file into a dataframe\r\n",
    "        file_path = os.path.join(directory, filename)\r\n",
    "        df = pd.read_csv(file_path)\r\n",
    "\r\n",
    "        # Iterate through the DataFrame rows\r\n",
    "        for idx, row in df.iterrows():\r\n",
    "            try:\r\n",
    "                # Extract values and handle NaNs\r\n",
    "                gene_symbol = row.get(\"gene_symbol\", \"\").strip()\r\n",
    "                gene_id = row.get(\"gene_id\", \"\")\r\n",
    "                disease_name = row.get(\"disease_name\", \"\").strip()\r\n",
    "                disease_id = row.get(\"disease_id\", \"\")\r\n",
    "                \r\n",
    "                # Concatenate DisGeNET with the source from the row\r\n",
    "                source_row = row.get(\"source\", \"\").strip()\r\n",
    "                source = f\"DisGeNET + {source_row}\"\r\n",
    "\r\n",
    "                score = row.get(\"score\", None)\r\n",
    "                pmid = row.get(\"pmid\", None)\r\n",
    "\r\n",
    "                # Convert pmid to int if it's not NaN\r\n",
    "                if isinstance(pmid, float) and math.isnan(pmid):\r\n",
    "                    pmid = None\r\n",
    "                elif isinstance(pmid, float):\r\n",
    "                    pmid = None\r\n",
    "                else:\r\n",
    "                    try:\r\n",
    "                        pmid = int(pmid) if pmid is not None else None\r\n",
    "                    except (ValueError, TypeError):\r\n",
    "                        pmid = None\r\n",
    "\r\n",
    "                # Check if gene and disease identifiers are not empty\r\n",
    "                if not gene_symbol or not gene_id or not disease_name or not disease_id:\r\n",
    "                    print(f\"Skipping row {idx} due to missing data\")\r\n",
    "                    continue\r\n",
    "\r\n",
    "                # Merge or create nodes with the source tag\r\n",
    "                merge_node_disease(\"Disease\", disease_name, disease_id, source)\r\n",
    "                merge_node_gene(\"Gene\", gene_symbol, gene_id, source)\r\n",
    "\r\n",
    "                # Create relationship between disease and gene with the source tag\r\n",
    "                merge_relationship(disease_id, gene_id, \"ASSOCIATION\", pmid, source, score)\r\n",
    "                \r\n",
    "            except Exception as e:\r\n",
    "                print(f\"Error processing row {idx}: {e}\")\r\n",
    "                print(filename)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DISEASE DB using one full data\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import json\r\n",
    "from neo4j import GraphDatabase\r\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\r\n",
    "\r\n",
    "# Neo4j connection details\r\n",
    "uri = \"bolt://localhost:7687\"\r\n",
    "user = \"neo4j\"\r\n",
    "password = \"12345678\"\r\n",
    "\r\n",
    "# Load the checkpoint file if it exists\r\n",
    "checkpoint_file = \"checkpoint.json\"\r\n",
    "if os.path.exists(checkpoint_file):\r\n",
    "    with open(checkpoint_file, 'r') as file:\r\n",
    "        checkpoint = json.load(file)\r\n",
    "else:\r\n",
    "    checkpoint = {}\r\n",
    "\r\n",
    "def process_batch(session, batch):\r\n",
    "    query = \"\"\"\r\n",
    "    UNWIND $batch AS row\r\n",
    "    MERGE (d:Disease {id: row.disease_id, name: row.disease_name})\r\n",
    "    MERGE (g:Gene {id: row.gene_id, symbol: row.gene_symbol})\r\n",
    "    MERGE (d)-[r:ASSOCIATION {source: row.source}]->(g)\r\n",
    "    SET r.score = row.score\r\n",
    "    \"\"\"\r\n",
    "    print(f\"Processing batch of {len(batch)} records\")\r\n",
    "    session.run(query, batch=batch)\r\n",
    "\r\n",
    "def process_file(file_path):\r\n",
    "    batch_size = 1000\r\n",
    "    with GraphDatabase.driver(uri, auth=(user, password)) as driver:\r\n",
    "        with driver.session() as session:\r\n",
    "            # Read the first row to determine the number of columns\r\n",
    "            first_row = pd.read_csv(file_path, sep=\"\\t\", header=None, nrows=1)\r\n",
    "\r\n",
    "            # Check if the file has a \"source\" column or only 5 columns\r\n",
    "            if first_row.shape[1] == 5:\r\n",
    "                # No \"source\" column, manually add it\r\n",
    "                column_names = [\"gene_id\", \"gene_symbol\", \"disease_id\", \"disease_name\", \"score\"]\r\n",
    "            elif first_row.shape[1] == 6:\r\n",
    "                # The \"source\" column is present\r\n",
    "                column_names = [\"gene_id\", \"gene_symbol\", \"disease_id\", \"disease_name\", \"score\", \"source\"]\r\n",
    "            else:\r\n",
    "                raise ValueError(f\"Unexpected number of columns: {first_row.shape[1]} in {file_path}\")\r\n",
    "\r\n",
    "            # Read CSV file in chunks\r\n",
    "            for chunk in pd.read_csv(file_path, sep=\"\\t\", header=None, chunksize=batch_size):\r\n",
    "                chunk.columns = column_names\r\n",
    "\r\n",
    "                # If the source column doesn't exist, add a default source\r\n",
    "                if \"source\" not in chunk.columns:\r\n",
    "                    chunk[\"source\"] = \"DiseaseDB\"  # Default source if missing\r\n",
    "\r\n",
    "                # If source exists, combine it with \"DiseaseDB\"\r\n",
    "                chunk['source'] = \"DiseaseDB + \" + chunk['source'].fillna(\"\").astype(str)\r\n",
    "                \r\n",
    "                # Convert the chunk to a batch and process it\r\n",
    "                batch = chunk.to_dict('records')\r\n",
    "                process_batch(session, batch)\r\n",
    "\r\n",
    "def main():\r\n",
    "    directory = \"data/Disease-db\"\r\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\r\n",
    "        future_to_file = {executor.submit(process_file, os.path.join(directory, filename)): filename \r\n",
    "                          for filename in os.listdir(directory) if filename.endswith(\".tsv\")}\r\n",
    "        \r\n",
    "        for future in as_completed(future_to_file):\r\n",
    "            filename = future_to_file[future]\r\n",
    "            try:\r\n",
    "                future.result()\r\n",
    "            except Exception as exc:\r\n",
    "                print(f'{filename} generated an exception: {exc}')\r\n",
    "            else:\r\n",
    "                print(f'{filename} processing completed')\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    main()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# OpenTargets import to Neo4j\r\n",
    "import os\r\n",
    "import sys\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "# Adjust the sys.path to include the parent directory if needed\r\n",
    "current_dir = os.getcwd()\r\n",
    "parent_dir = os.path.dirname(current_dir)\r\n",
    "if parent_dir not in sys.path:\r\n",
    "    sys.path.append(parent_dir)\r\n",
    "\r\n",
    "# Import custom module after adjusting sys.path\r\n",
    "import opentarget_disease_filter\r\n",
    "#import filtered_diseases\r\n",
    "\r\n",
    "# Neo4j connection details\r\n",
    "uri = \"bolt://localhost:7687\"\r\n",
    "user = \"neo4j\"\r\n",
    "password = \"12345678\"\r\n",
    "graph = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "\r\n",
    "def merge_node_disease(label, disease_name, disease_id, source):\r\n",
    "    merge_query = f\"\"\"\r\n",
    "    MERGE (n:{label} {{name: $name, id: $id}})\r\n",
    "    ON CREATE SET n.source = $source\r\n",
    "    RETURN n\r\n",
    "    \"\"\"\r\n",
    "    with graph.session() as session:\r\n",
    "        return session.run(merge_query, name=disease_name, id=disease_id, source=source).single()\r\n",
    "\r\n",
    "def merge_node_target(label, gene_symbol, source):\r\n",
    "    merge_query = f\"\"\"\r\n",
    "    MERGE (n:{label} {{symbol: $symbol}})\r\n",
    "    ON CREATE SET n.source = $source\r\n",
    "    RETURN n\r\n",
    "    \"\"\"\r\n",
    "    with graph.session() as session:\r\n",
    "        return session.run(merge_query, symbol=gene_symbol, source=source).single()\r\n",
    "\r\n",
    "def merge_relationship(disease_name, gene_symbol, association_type, score, source):\r\n",
    "    properties = [\"source: $source\"]\r\n",
    "    params = {'disease_name': disease_name, 'gene_symbol': gene_symbol, 'source': source}\r\n",
    "    \r\n",
    "    if score is not None:\r\n",
    "        properties.append(\"score: $score\")\r\n",
    "        params['score'] = score\r\n",
    "\r\n",
    "    properties_str = \", \".join(properties)\r\n",
    "    \r\n",
    "    relationship_query = f\"\"\"\r\n",
    "    MATCH (d:Disease {{name: $disease_name}})\r\n",
    "    MATCH (g:Gene {{symbol: $gene_symbol}})\r\n",
    "    MERGE (d)-[r:{association_type} {{{properties_str}}}]->(g)\r\n",
    "    RETURN r\r\n",
    "    \"\"\"\r\n",
    "    with graph.session() as session:\r\n",
    "        return session.run(relationship_query, **params).single()\r\n",
    "\r\n",
    "directory = \"data/OpenTargets/data\"\r\n",
    "disease_names = opentarget_disease_filter.disease_names_filter\r\n",
    "\r\n",
    "for filename in os.listdir(directory):\r\n",
    "    if filename.endswith(\".tsv\"):\r\n",
    "        file_path = os.path.join(directory, filename)\r\n",
    "        # Load the TSV file into a dataframe\r\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\", header=0)\r\n",
    "        \r\n",
    "        for idx, row in df.iterrows():\r\n",
    "            try:\r\n",
    "                # Extract values and handle NaNs\r\n",
    "                gene_symbol = row.get(\"symbol\", \"\")\r\n",
    "                score = row.get(\"globalScore\", None)\r\n",
    "                \r\n",
    "                # Extract disease_id from the filename and map it to disease_name\r\n",
    "                match = re.search(r'OT-(.*?)-associated', filename)\r\n",
    "                if match:\r\n",
    "                    disease_id = match.group(1)\r\n",
    "                disease_name = disease_names.get(disease_id, None)\r\n",
    "                \r\n",
    "                if disease_name:\r\n",
    "                    print(\"imported\", disease_name)\r\n",
    "                    # Combine OpenTargets with the source column (if available)\r\n",
    "                    source = \"OpenTargets + \" + row.get(\"source\", \"\").strip()\r\n",
    "\r\n",
    "                    # Merge disease node, gene node, and the relationship with source\r\n",
    "                    merge_node_disease(\"Disease\", disease_name, disease_id, source)\r\n",
    "                    merge_node_target(\"Gene\", gene_symbol, source)\r\n",
    "                    merge_relationship(disease_name, gene_symbol, \"ASSOCIATION\", score, source)\r\n",
    "            except Exception as e:\r\n",
    "                print(f\"Error processing row {idx} in file {filename}: {e}\")\r\n",
    "\r\n",
    "print(\"Data import completed.\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###INDRA import to Neo4j\r\n",
    "import pandas as pd\r\n",
    "import ast\r\n",
    "import os\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "# Function to detect the type of node (disease, chemical, or gene)\r\n",
    "def detect_neo4j_node_type(my_dict):\r\n",
    "    node_type = \"Entity\"\r\n",
    "    if \"MESH\" in my_dict:\r\n",
    "        node_type = \"Disease\"\r\n",
    "    if \"CHEBI\" in my_dict:\r\n",
    "        node_type = \"Chemical\"\r\n",
    "    if \"HGNC\" in my_dict:\r\n",
    "        node_type = \"Gene\"\r\n",
    "    return node_type \r\n",
    "\r\n",
    "# Neo4j connection details\r\n",
    "uri = \"bolt://localhost:7687\"\r\n",
    "user = \"neo4j\"\r\n",
    "password = \"12345678\"\r\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "\r\n",
    "# Function to upload triples to Neo4j with a source tag\r\n",
    "def upload_triples_neo4j(triple, disease_name):\r\n",
    "    print(\"Uploading triples in Neo4j\")\r\n",
    "    with driver.session() as session:\r\n",
    "        try:\r\n",
    "            subj = triple['subj']\r\n",
    "            obj = triple['obj']\r\n",
    "            rel_type = triple['type']\r\n",
    "            subj_type = detect_neo4j_node_type(triple[\"subj_namespace\"])\r\n",
    "            obj_type = detect_neo4j_node_type(triple[\"obj_namespace\"])\r\n",
    "\r\n",
    "            # Process PMIDs handling single integers, lists, and NaN\r\n",
    "            pmids = []\r\n",
    "            pmids_string_list = triple['pmids']\r\n",
    "\r\n",
    "            if pd.notna(pmids_string_list):\r\n",
    "                if isinstance(pmids_string_list, (int, float)):\r\n",
    "                    pmids = [int(pmids_string_list)]\r\n",
    "                elif isinstance(pmids_string_list, str):\r\n",
    "                    if pmids_string_list.startswith(\"[\") and pmids_string_list.endswith(\"]\"):\r\n",
    "                        pmids = ast.literal_eval(pmids_string_list)\r\n",
    "                        pmids = [int(float(pmid)) for pmid in pmids if isinstance(pmid, (int, float))]\r\n",
    "                    else:\r\n",
    "                        pmids = [int(float(pmids_string_list))]\r\n",
    "\r\n",
    "            evid = triple[\"evid_sentence\"] if triple[\"evid_sentence\"] else \"NoEvidence\"\r\n",
    "            source = \"INDRA + \" + triple.get('source', 'Unknown')\r\n",
    "\r\n",
    "            cypher_query = f\"\"\"\r\n",
    "            MERGE (a:{subj_type} {{name: $subj}})\r\n",
    "            MERGE (b:{obj_type} {{name: $obj}})\r\n",
    "            MERGE (a)-[r:{rel_type} {{pmids: $pmids, disease_name: $disease_name, evid_sentence: $evid_sentence, source: $source}}]->(b)\r\n",
    "            \"\"\"\r\n",
    "            session.run(cypher_query, subj=subj, obj=obj, pmids=pmids, disease_name=disease_name, evid_sentence=evid, source=source)\r\n",
    "\r\n",
    "        except Exception as e:\r\n",
    "            print(\"Cannot import this row to Neo4j\", e)\r\n",
    "\r\n",
    "# Close the driver\r\n",
    "driver.close()\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    directory = \"data/INDRA/data\"\r\n",
    "    api_key = \"f2be320e-22f7-471a-b457-326a3ebb5a84\"\r\n",
    "    \r\n",
    "    for filename in os.listdir(directory):\r\n",
    "        if filename.endswith('.xlsx'):\r\n",
    "            file_path = os.path.join(directory, filename)\r\n",
    "            disease_name = filename.split(\".xlsx\")[0]\r\n",
    "            # Load the Excel file into a DataFrame\r\n",
    "            df = pd.read_excel(file_path)\r\n",
    "            \r\n",
    "            # Data cleaning: Drop rows where 'subj', 'obj', 'pmids' are missing, and filter 'belief' > 0.85\r\n",
    "            df = df.dropna(subset=['subj', 'obj', 'pmids', 'score (belief)'])\r\n",
    "            df = df[df['pmids'].astype(bool)]  # Further filter out any rows where pmids is empty\r\n",
    "            df = df[df['score (belief)'] > 0.85]       # Filter rows where belief is > 0.85\r\n",
    "\r\n",
    "            # Process each row in the cleaned DataFrame\r\n",
    "            for index, row in df.iterrows():\r\n",
    "                upload_triples_neo4j(row, disease_name)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###import DrugBank###\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "# Function to detect the Neo4j node type (not used in this case but kept for flexibility)\r\n",
    "def detect_neo4j_node_type(my_dict):\r\n",
    "    node_type = \"Entity\"\r\n",
    "    if \"MESH\" in my_dict:\r\n",
    "        node_type = \"disease\"\r\n",
    "    if \"CHEBI\" in my_dict:\r\n",
    "        node_type = \"chemical\"\r\n",
    "    if \"HGNC\" in my_dict:\r\n",
    "        node_type = \"gene\"\r\n",
    "    return node_type\r\n",
    "\r\n",
    "# Neo4j connection details\r\n",
    "uri = \"bolt://localhost:7687\"\r\n",
    "user = \"neo4j\"\r\n",
    "password = \"12345678\"\r\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "\r\n",
    "# Function to upload triples to Neo4j with a source tag\r\n",
    "def upload_triples_neo4j(triple, disease_name):\r\n",
    "    print(f\"Uploading triples for disease: {disease_name}\")\r\n",
    "    with driver.session() as session:\r\n",
    "        try:\r\n",
    "            # Extract values from the triple\r\n",
    "            subj = disease_name  # The disease name is the subject\r\n",
    "            subj_type = \"Disease\"  # Type of the subject node is Disease\r\n",
    "            obj = triple['Drug Name']  # The drug is the object\r\n",
    "            obj_type = \"Drug\"  # Type of the object node is Drug\r\n",
    "            rel_type = \"ASSOCIATION\"  # Type of the relationship\r\n",
    "            drug_id = triple[\"Primary ID\"]  # Drug ID from DrugBank\r\n",
    "            pmid = int(triple[\"PubMed ID\"])  # PubMed ID\r\n",
    "            \r\n",
    "            # Define the source tag for DrugBank\r\n",
    "            source = \"DrugBank + \" + triple.get('Source', 'Unknown')\r\n",
    "\r\n",
    "            # Create nodes and relationships, including the source and pmid\r\n",
    "            cypher_query = f\"\"\"\r\n",
    "            MERGE (a:{subj_type} {{name: $subj}})\r\n",
    "            MERGE (b:{obj_type} {{name: $obj, id: $drug_id}})\r\n",
    "            MERGE (a)-[r:{rel_type} {{pmid: $pmid, source: $source}}]->(b)\r\n",
    "            \"\"\"\r\n",
    "\r\n",
    "            session.run(cypher_query, subj=subj, obj=obj, drug_id=drug_id, pmid=pmid, source=source)\r\n",
    "\r\n",
    "        except Exception as e:\r\n",
    "            print(f\"Cannot import row for disease {disease_name}: {e}\")\r\n",
    "\r\n",
    "# Close the driver\r\n",
    "driver.close()\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    directory = \"data/DRUGBANK/csv_output\"\r\n",
    "    \r\n",
    "    for filename in os.listdir(directory):\r\n",
    "        if filename.endswith('.csv'):\r\n",
    "            file_path = os.path.join(directory, filename)\r\n",
    "            disease_name = filename.split(\".csv\")[0]  # Extract disease name from filename\r\n",
    "            # Load the CSV file into a DataFrame\r\n",
    "            df = pd.read_csv(file_path)\r\n",
    "            # Process each row in the DataFrame\r\n",
    "            for index, row in df.iterrows():\r\n",
    "                upload_triples_neo4j(row, disease_name)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Import Pubtator results ###\r\n",
    "import pandas as pd\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "# Replace these with your actual connection details\r\n",
    "uri = \"bolt://localhost:7687\"\r\n",
    "user = \"neo4j\"\r\n",
    "password = \"12345678\"\r\n",
    "\r\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "\r\n",
    "def validate_type(node_type):\r\n",
    "    \"\"\"Validates the node type, returning 'undefined' if the type is an integer or None.\"\"\"\r\n",
    "    if isinstance(node_type, int) or node_type is None:\r\n",
    "        return \"undefined\"\r\n",
    "    return node_type\r\n",
    "\r\n",
    "def upload_triples_neo4j(triple):\r\n",
    "    \"\"\"Uploads a triple to Neo4j.\"\"\"\r\n",
    "    print(f\"Uploading triple: {triple['node1_text']} -[{triple['relation_type']}]-> {triple['node2_text']}\")\r\n",
    "    with driver.session() as session:\r\n",
    "        try:\r\n",
    "            subj = triple['node1_text']\r\n",
    "            subj_type = validate_type(triple['role1_type'])\r\n",
    "            obj = triple['node2_text']\r\n",
    "            obj_type = validate_type(triple['role2_type'])\r\n",
    "            rel_type = triple['relation_type'].upper()\r\n",
    "            pmid = int(triple['pmid'])\r\n",
    "            score = float(triple['score'])\r\n",
    "            evidence = triple['evidence']\r\n",
    "\r\n",
    "            # Combine PubTator with additional source information (if available)\r\n",
    "            source = \"PubTator + \" + triple.get('source', 'Unknown')\r\n",
    "\r\n",
    "            # Create nodes and relationship with additional properties including source\r\n",
    "            cypher_query = f\"\"\"\r\n",
    "            MERGE (a:{subj_type} {{name: $subj}})\r\n",
    "            MERGE (b:{obj_type} {{name: $obj}})\r\n",
    "            MERGE (a)-[r:{rel_type} {{pmid: $pmid, score: $score, evidence: $evidence, source: $source}}]->(b)\r\n",
    "            \"\"\"\r\n",
    "\r\n",
    "            session.run(cypher_query, subj=subj, obj=obj, pmid=pmid, score=score, evidence=evidence, source=source)\r\n",
    "        except Exception as e:\r\n",
    "            print(\"Cannot import this row to Neo4j:\", e)\r\n",
    "\r\n",
    "# Close the driver connection\r\n",
    "driver.close()\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    # Load the Excel file into a DataFrame (replace with your actual file path)\r\n",
    "    excel_file_path = \"data/PubTator/pmc_triples_100.xlsx\"  # Replace with the actual path\r\n",
    "\r\n",
    "    df = pd.read_excel(excel_file_path)\r\n",
    "\r\n",
    "    # Process each row in the DataFrame and upload to Neo4j\r\n",
    "    for index, row in df.iterrows():\r\n",
    "        upload_triples_neo4j(row)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Upload iTEXTMine to Neo4j\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "class Neo4jUploader:\r\n",
    "    \r\n",
    "    def __init__(self, uri, user, password):\r\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "    \r\n",
    "    def close(self):\r\n",
    "        self.driver.close()\r\n",
    "\r\n",
    "    # Upload kinase-substrate data\r\n",
    "    def upload_kinase_substrate(self, dataframe, source):\r\n",
    "        with self.driver.session() as session:\r\n",
    "            for index, row in dataframe.iterrows():\r\n",
    "                session.write_transaction(self._create_kinase_substrate_relationship, row['kinase'], row['relation'], row['substrate'], row['evidence'], source)\r\n",
    "\r\n",
    "    # Upload gene-miRNA data\r\n",
    "    def upload_gene_mirna(self, dataframe, source):\r\n",
    "        with self.driver.session() as session:\r\n",
    "            for index, row in dataframe.iterrows():\r\n",
    "                session.write_transaction(self._create_gene_mirna_relationship, row['gene'], row['relation'], row['mirna'], row['evidence'], source)\r\n",
    "\r\n",
    "    # Upload gene-disease-drug response data\r\n",
    "    def upload_gene_disease_drug_response(self, dataframe, source):\r\n",
    "        with self.driver.session() as session:\r\n",
    "            for index, row in dataframe.iterrows():\r\n",
    "                session.write_transaction(self._create_gene_disease_drug_relationship, row['gene'], row['disease'], row['drug_response'], row['evidence'], source)\r\n",
    "\r\n",
    "    # Create kinase-substrate relationship\r\n",
    "    @staticmethod\r\n",
    "    def _create_kinase_substrate_relationship(tx, kinase, relation, substrate, evidence, source):\r\n",
    "        query = \"\"\"\r\n",
    "        MERGE (k:Kinase {name: $kinase, source: $source})\r\n",
    "        MERGE (s:Substrate {name: $substrate, source: $source})\r\n",
    "        MERGE (k)-[r:RELATION {type: $relation, evidence: $evidence, source: $source}]->(s)\r\n",
    "        \"\"\"\r\n",
    "        tx.run(query, kinase=kinase, relation=relation, substrate=substrate, evidence=evidence, source=source)\r\n",
    "\r\n",
    "    # Create gene-miRNA relationship\r\n",
    "    @staticmethod\r\n",
    "    def _create_gene_mirna_relationship(tx, gene, relation, mirna, evidence, source):\r\n",
    "        query = \"\"\"\r\n",
    "        MERGE (g:Gene {name: $gene, source: $source})\r\n",
    "        MERGE (m:miRNA {name: $mirna, source: $source})\r\n",
    "        MERGE (g)-[r:RELATION {type: $relation, evidence: $evidence, source: $source}]->(m)\r\n",
    "        \"\"\"\r\n",
    "        tx.run(query, gene=gene, relation=relation, mirna=mirna, evidence=evidence, source=source)\r\n",
    "\r\n",
    "    # Create gene-disease-drug response relationship\r\n",
    "    @staticmethod\r\n",
    "    def _create_gene_disease_drug_relationship(tx, gene, disease, drug_response, evidence, source):\r\n",
    "        query = \"\"\"\r\n",
    "        MERGE (g:Gene {name: $gene, source: $source})\r\n",
    "        MERGE (d:Disease {name: $disease, source: $source})\r\n",
    "        MERGE (dr:DrugResponse {type: $drug_response, source: $source})\r\n",
    "        MERGE (g)-[:DISEASE {evidence: $evidence, source: $source}]->(d)\r\n",
    "        MERGE (d)-[:RESPONSE {evidence: $evidence, source: $source}]->(dr)\r\n",
    "        \"\"\"\r\n",
    "        tx.run(query, gene=gene, disease=disease, drug_response=drug_response, evidence=evidence, source=source)\r\n",
    "\r\n",
    "# Function to extract source from file path and prepend 'iTextMine + '\r\n",
    "def extract_source_from_path(filepath):\r\n",
    "    \"\"\"Extract the source name from the file name or directory, prepending 'iTextMine + '.\"\"\"\r\n",
    "    base_filename = os.path.basename(filepath)\r\n",
    "    # Prepend 'iTextMine + ' to the extracted source\r\n",
    "    source_name = \"iTextMine + \" + os.path.splitext(base_filename)[0]  # Remove file extension\r\n",
    "    return source_name\r\n",
    "\r\n",
    "# Main function to run the uploads\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    \r\n",
    "    # Connection parameters for Neo4j\r\n",
    "    uri = \"bolt://localhost:7687\"  # Update with your Neo4j instance URI\r\n",
    "    user = \"neo4j\"  # Neo4j username\r\n",
    "    password = \"12345678\"  # Neo4j password\r\n",
    "\r\n",
    "    # Instantiate the uploader class\r\n",
    "    uploader = Neo4jUploader(uri, user, password)\r\n",
    "    \r\n",
    "    try:\r\n",
    "        # Define the CSV file paths (update these paths with your actual file locations)\r\n",
    "        kinase_substrate_csv = \"data/iTextMine/data/Kinase-Substrate_Triples_with_Evidence.csv\"\r\n",
    "        gene_mirna_csv = \"data/iTextMine/data/Gene-miRNA_Triples_with_Evidence.csv\"\r\n",
    "        gene_disease_drug_csv = \"data/iTextMine/data/Gene-Disease-DrugResponse_Triples_with_Evidence.csv\"\r\n",
    "        \r\n",
    "        # Automatically extract the source from the file name or path with 'iTextMine + '\r\n",
    "        source_kinase_substrate = extract_source_from_path(kinase_substrate_csv)\r\n",
    "        source_gene_mirna = extract_source_from_path(gene_mirna_csv)\r\n",
    "        source_gene_disease_drug = extract_source_from_path(gene_disease_drug_csv)\r\n",
    "\r\n",
    "        # Load the CSVs into pandas DataFrames\r\n",
    "        kinase_substrate_df = pd.read_csv(kinase_substrate_csv)\r\n",
    "        gene_mirna_df = pd.read_csv(gene_mirna_csv)\r\n",
    "        gene_disease_drug_df = pd.read_csv(gene_disease_drug_csv)\r\n",
    "\r\n",
    "        # Upload the data to Neo4j with extracted source information\r\n",
    "        print(f\"Uploading kinase-substrate triples from {source_kinase_substrate}...\")\r\n",
    "        uploader.upload_kinase_substrate(kinase_substrate_df, source_kinase_substrate)\r\n",
    "        \r\n",
    "        print(f\"Uploading gene-miRNA triples from {source_gene_mirna}...\")\r\n",
    "        uploader.upload_gene_mirna(gene_mirna_df, source_gene_mirna)\r\n",
    "        \r\n",
    "        print(f\"Uploading gene-disease-drug response triples from {source_gene_disease_drug}...\")\r\n",
    "        uploader.upload_gene_disease_drug_response(gene_disease_drug_df, source_gene_disease_drug)\r\n",
    "        \r\n",
    "        print(\"Data uploaded successfully!\")\r\n",
    "    \r\n",
    "    finally:\r\n",
    "        # Close the Neo4j connection\r\n",
    "        uploader.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Sherpa upload\r\n",
    "import os\r\n",
    "from bel_json_importer.n4j_meta import Neo4jClient\r\n",
    "from bel_json_importer.n4j_bel import Neo4jBel\r\n",
    "paths = []\r\n",
    "for path, _, files in os.walk(\"data/Sherpa\"): #substitute it with \"data\" to laod covid and NDD and sherpa triples only\r\n",
    "    for file in files:\r\n",
    "        print(file)\r\n",
    "        if file.endswith(\".json\"):\r\n",
    "            print(path)\r\n",
    "            paths.append(os.path.join(path, file))\r\n",
    "neo = Neo4jClient(\r\n",
    "    uri=\"bolt://localhost:7687\", database=\"neo4j\", user=\"neo4j\", password=\"12345678\"\r\n",
    ")\r\n",
    "#Add all three graphs covid ad pd and comorbidity\r\n",
    "n4jbel = Neo4jBel(client=neo)\r\n",
    "for path in paths:\r\n",
    "    n4jbel.import_json(input_path=path, update_from_protein2gene=False) #Maria added True\r\n",
    "\r\n",
    "print(\"Done\")\r\n",
    "\r\n",
    "#remember to add this fr convininece:\r\n",
    "\r\n",
    "'match(n)-[r]->(m) where \"sherpa\" in r.annotationDatasource set r.source = \"sherpa\"'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#CBM uplaod\r\n",
    "import os\r\n",
    "from bel_json_importer.n4j_meta import Neo4jClient\r\n",
    "from bel_json_importer.n4j_bel import Neo4jBel\r\n",
    "paths = []\r\n",
    "for path, _, files in os.walk(\"data/CBM/data\"): #substitute it with \"data\" to laod covid and NDD and sherpa triples only\r\n",
    "    for file in files:\r\n",
    "        print(file)\r\n",
    "        if file.endswith(\".json\"):\r\n",
    "            print(path)\r\n",
    "            paths.append(os.path.join(path, file))\r\n",
    "neo = Neo4jClient(\r\n",
    "    uri=\"bolt://localhost:7687\", database=\"neo4j\", user=\"neo4j\", password=\"12345678\"\r\n",
    ")\r\n",
    "#Add all three graphs covid ad pd and comorbidity\r\n",
    "n4jbel = Neo4jBel(client=neo)\r\n",
    "for path in paths:\r\n",
    "    n4jbel.import_json(input_path=path, update_from_protein2gene=False) #Maria added True\r\n",
    "\r\n",
    "print(\"Done\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#UPLOAD SCAI AD PD NDD COVID graph\r\n",
    "import os\r\n",
    "from bel_json_importer.n4j_meta import Neo4jClient\r\n",
    "from bel_json_importer.n4j_bel import Neo4jBel\r\n",
    "paths = []\r\n",
    "for path, _, files in os.walk(\"data/SCAI-graphs\"): #substitute it with \"data\" to laod covid and NDD and sherpa triples only\r\n",
    "    for file in files:\r\n",
    "        print(file)\r\n",
    "        if file.endswith(\".json\"):\r\n",
    "            print(path)\r\n",
    "            paths.append(os.path.join(path, file))\r\n",
    "neo = Neo4jClient(\r\n",
    "    uri=\"bolt://localhost:7687\", database=\"neo4j\", user=\"neo4j\", password=\"12345678\"\r\n",
    ")\r\n",
    "#Add all three graphs covid ad pd and comorbidity\r\n",
    "n4jbel = Neo4jBel(client=neo)\r\n",
    "for path in paths:\r\n",
    "    n4jbel.import_json(input_path=path, update_from_protein2gene=False) #Maria added True\r\n",
    "\r\n",
    "print(\"Done\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KEGG UPLOAD: INCOMPLETE data!!!!\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "# Load the CSV file into a pandas DataFrame\r\n",
    "file_path = r'C:\\Users\\nbabaiha\\Documents\\GitHub\\COMMUTE\\commute\\compare-curated-sources\\kegg-api-responses\\all_kegg_data_final.csv'\r\n",
    "data = pd.read_csv(file_path)\r\n",
    "\r\n",
    "# Verify if the file has 'Name' and 'Gene/Drug' columns\r\n",
    "if 'Name' not in data.columns or 'Gene/Drug' not in data.columns:\r\n",
    "    raise ValueError(\"The file must contain 'Name' and 'Gene/Drug' columns.\")\r\n",
    "\r\n",
    "# Function to extract the drug ID from square brackets, e.g., [DR:D00781]\r\n",
    "def extract_drug_id(gene_drug):\r\n",
    "    match = re.search(r'\\[(DR:\\w+)\\]', gene_drug)\r\n",
    "    if match:\r\n",
    "        return match.group(1)  # Return the drug ID (e.g., 'DR:D00781')\r\n",
    "    return None\r\n",
    "\r\n",
    "# Function to extract the gene name from parentheses, e.g., (AD3)\r\n",
    "def extract_gene_name(gene_drug):\r\n",
    "    # match = re.search(r'\\((.*?)\\)', gene_drug)\r\n",
    "    # if match:\r\n",
    "    #     return match.group(1)  # Return the gene name (e.g., 'AD3')\r\n",
    "    # return None\r\n",
    "    return(gene_drug)\r\n",
    "\r\n",
    "# Function to clean up the name by removing brackets or parentheses\r\n",
    "def clean_name(gene_drug):\r\n",
    "    return re.sub(r'\\s*\\[.*?\\]|\\(.*?\\)', '', gene_drug).strip()\r\n",
    "\r\n",
    "# Connect to Neo4j\r\n",
    "def connect_to_neo4j(uri, user, password):\r\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "    return driver\r\n",
    "\r\n",
    "# Function to create nodes and relationships in Neo4j with a 'source' property\r\n",
    "def upload_triples_to_neo4j(driver, triples):\r\n",
    "    with driver.session() as session:\r\n",
    "        for name, gene_drug in triples:\r\n",
    "            cleaned_gene_drug_name = clean_name(gene_drug)  # Cleaned name (e.g., 'Entacapone')\r\n",
    "            drug_id = extract_drug_id(gene_drug)  # Extract drug ID (e.g., 'DR:D00781')\r\n",
    "            gene_name = extract_gene_name(gene_drug)  # Extract gene name (e.g., 'AD3')\r\n",
    "\r\n",
    "            # Check for debug output to verify the extraction\r\n",
    "            print(f\"Processed: {gene_drug} -> Gene: {gene_name}, Drug ID: {drug_id}\")\r\n",
    "\r\n",
    "            if drug_id:  # If the drug ID exists\r\n",
    "                session.run(\"\"\"\r\n",
    "                MERGE (n:Disease {name: $name})\r\n",
    "                MERGE (g:Drug {name: $cleaned_gene_drug_name, drug_id: $drug_id})\r\n",
    "                MERGE (n)-[r:ASSOCIATION]->(g)\r\n",
    "                ON CREATE SET r.source = 'KEGG'\r\n",
    "                \"\"\", name=name, cleaned_gene_drug_name=cleaned_gene_drug_name, drug_id=drug_id)\r\n",
    "            else:  # If it's a gene (contains parentheses)\r\n",
    "                print(f\"Creating Gene: {gene_name}\")  # Add debug output to confirm\r\n",
    "                session.run(\"\"\"\r\n",
    "                MERGE (n:Disease {name: $name})\r\n",
    "                MERGE (g:Gene {name: $gene_name})\r\n",
    "                MERGE (n)-[r:ASSOCIATION]->(g)\r\n",
    "                ON CREATE SET r.source = 'KEGG'\r\n",
    "                \"\"\", name=name, gene_name=gene_name)\r\n",
    "            # else:  # If neither drug ID nor gene, it's a default GeneDrug\r\n",
    "            #     session.run(\"\"\"\r\n",
    "            #     MERGE (n:Disease {name: $name})\r\n",
    "            #     MERGE (g:GeneDrug {name: $cleaned_gene_drug_name})\r\n",
    "            #     MERGE (n)-[r:ASSOCIATION]->(g)\r\n",
    "            #     ON CREATE SET r.source = 'KEGG'\r\n",
    "            #     \"\"\", name=name, cleaned_gene_drug_name=cleaned_gene_drug_name)\r\n",
    "\r\n",
    "        print(\"Upload completed successfully!\")\r\n",
    "\r\n",
    "# Get the unique triples from the CSV file\r\n",
    "triples = list(data[['Name', 'Gene/Drug']].dropna().drop_duplicates().itertuples(index=False, name=None))\r\n",
    "\r\n",
    "# Your Neo4j credentials and connection details\r\n",
    "neo4j_uri = \"bolt://localhost:7687\"  # Replace with your actual Neo4j URI\r\n",
    "neo4j_user = \"neo4j\"  # Replace with your Neo4j username\r\n",
    "neo4j_password = \"12345678\"  # Replace with your Neo4j password\r\n",
    "\r\n",
    "# Connect to the Neo4j instance\r\n",
    "driver = connect_to_neo4j(neo4j_uri, neo4j_user, neo4j_password)\r\n",
    "\r\n",
    "# Upload the triples to Neo4j\r\n",
    "upload_triples_to_neo4j(driver, triples)\r\n",
    "\r\n",
    "# Close the Neo4j driver connection\r\n",
    "driver.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#IMPORT KEEGG COMPELTE DATA\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import os\r\n",
    "from neo4j import GraphDatabase\r\n",
    "\r\n",
    "# Define the directory containing the CSV files\r\n",
    "csv_dir = file_path = r'C:\\Users\\nbabaiha\\Documents\\GitHub\\COMMUTE\\commute\\compare-curated-sources\\kegg-api-responses-complete\\updated_csv_files'\r\n",
    "\r\n",
    "\r\n",
    "# Function to clean up information\r\n",
    "def clean_name(name):\r\n",
    "    return re.sub(r'\\s*\\[.*?\\]|\\(.*?\\)', '', name).strip()\r\n",
    "\r\n",
    "# Connect to Neo4j\r\n",
    "def connect_to_neo4j(uri, user, password):\r\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\r\n",
    "    return driver\r\n",
    "\r\n",
    "# Function to create nodes and relationships in Neo4j\r\n",
    "def upload_nodes_and_relationships(driver, records):\r\n",
    "    with driver.session() as session:\r\n",
    "        for record in records:\r\n",
    "            name = record.get('NAME', '')\r\n",
    "\r\n",
    "            # Ensure each field is a string before splitting, using empty list if None\r\n",
    "            genes = str(record.get('GENE_SYMBOL', '')).split('; ') if isinstance(record.get('GENE_SYMBOL', ''), str) else []\r\n",
    "            drugs = str(record.get('DRUG', '')).split('; ') if isinstance(record.get('DRUG', ''), str) else []\r\n",
    "            pathways = str(record.get('PATHWAY', '')).split('; ') if isinstance(record.get('PATHWAY', ''), str) else []\r\n",
    "            networks = str(record.get('NETWORK', '')).split('; ') if isinstance(record.get('NETWORK', ''), str) else []\r\n",
    "\r\n",
    "            # Log the processed data to confirm it is being read correctly\r\n",
    "            print(f\"Processing Disease Node: {name}\")\r\n",
    "            print(f\"  Genes: {genes}\")\r\n",
    "            print(f\"  Drugs: {drugs}\")\r\n",
    "            print(f\"  Pathways: {pathways}\")\r\n",
    "            print(f\"  Networks: {networks}\")\r\n",
    "\r\n",
    "            # Create NAME node (Disease)\r\n",
    "            session.run(\"\"\"\r\n",
    "            MERGE (n:Disease {name: $name})\r\n",
    "            \"\"\", name=name)\r\n",
    "            \r\n",
    "            # Create and relate each gene to the disease\r\n",
    "            for gene in genes:\r\n",
    "                if gene:\r\n",
    "                    cleaned_gene = clean_name(gene)\r\n",
    "                    print(f\"  Creating Gene Node: {cleaned_gene}\")\r\n",
    "                    session.run(\"\"\"\r\n",
    "                    MERGE (g:Gene {name: $cleaned_gene})\r\n",
    "                    MERGE (n:Disease {name: $name})\r\n",
    "                    MERGE (n)-[r:ASSOCIATION]->(g)\r\n",
    "                    ON CREATE SET r.source = 'KEGG'\r\n",
    "                    \"\"\", cleaned_gene=cleaned_gene, name=name)\r\n",
    "\r\n",
    "            # Create and relate each drug to the disease\r\n",
    "            for drug in drugs:\r\n",
    "                if drug:\r\n",
    "                    cleaned_drug = clean_name(drug)\r\n",
    "                    print(f\"  Creating Drug Node: {cleaned_drug}\")\r\n",
    "                    session.run(\"\"\"\r\n",
    "                    MERGE (d:Drug {name: $cleaned_drug})\r\n",
    "                    MERGE (n:Disease {name: $name})\r\n",
    "                    MERGE (n)-[r:TREATED_BY]->(d)\r\n",
    "                    ON CREATE SET r.source = 'KEGG'\r\n",
    "                    \"\"\", cleaned_drug=cleaned_drug, name=name)\r\n",
    "\r\n",
    "            # Create and relate each pathway to the disease\r\n",
    "            for pathway in pathways:\r\n",
    "                if pathway:\r\n",
    "                    cleaned_pathway = clean_name(pathway)\r\n",
    "                    print(f\"  Creating Pathway Node: {cleaned_pathway}\")\r\n",
    "                    session.run(\"\"\"\r\n",
    "                    MERGE (p:Pathway {name: $cleaned_pathway})\r\n",
    "                    MERGE (n:Disease {name: $name})\r\n",
    "                    MERGE (n)-[r:INVOLVED_IN]->(p)\r\n",
    "                    ON CREATE SET r.source = 'KEGG'\r\n",
    "                    \"\"\", cleaned_pathway=cleaned_pathway, name=name)\r\n",
    "\r\n",
    "            # Create and relate each network to the disease\r\n",
    "            for network in networks:\r\n",
    "                if network:\r\n",
    "                    cleaned_network = clean_name(network)\r\n",
    "                    print(f\"  Creating Network Node: {cleaned_network}\")\r\n",
    "                    session.run(\"\"\"\r\n",
    "                    MERGE (nw:Network {name: $cleaned_network})\r\n",
    "                    MERGE (n:Disease {name: $name})\r\n",
    "                    MERGE (n)-[r:PART_OF_NETWORK]->(nw)\r\n",
    "                    ON CREATE SET r.source = 'KEGG'\r\n",
    "                    \"\"\", cleaned_network=cleaned_network, name=name)\r\n",
    "\r\n",
    "        print(\"Upload completed successfully!\")\r\n",
    "\r\n",
    "# Your Neo4j credentials and connection details\r\n",
    "neo4j_uri = \"bolt://localhost:7687\"\r\n",
    "neo4j_user = \"neo4j\"\r\n",
    "neo4j_password = \"12345678\"\r\n",
    "\r\n",
    "# Connect to the Neo4j instance\r\n",
    "driver = connect_to_neo4j(neo4j_uri, neo4j_user, neo4j_password)\r\n",
    "\r\n",
    "# Process each CSV file in the directory\r\n",
    "for filename in os.listdir(csv_dir):\r\n",
    "    if filename.endswith('.csv'):\r\n",
    "        file_path = os.path.join(csv_dir, filename)\r\n",
    "        data = pd.read_csv(file_path)\r\n",
    "\r\n",
    "        if 'NAME' not in data.columns:\r\n",
    "            raise ValueError(f\"The file {filename} must contain a 'NAME' column.\")\r\n",
    "\r\n",
    "        # Create a list of dictionaries for each row in the file\r\n",
    "        records = data.to_dict('records')\r\n",
    "\r\n",
    "        # Upload nodes and relationships for each record\r\n",
    "        print(f\"Uploading records from {filename} to Neo4j...\")\r\n",
    "        upload_nodes_and_relationships(driver, records)\r\n",
    "\r\n",
    "# Close the Neo4j driver connection\r\n",
    "driver.close()\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Queries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### get triples by source\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "MATCH (a)-[r]->(b)\r\n",
    "WHERE r.source STARTS WITH 'iTextMine'\r\n",
    "RETURN a.name AS Subject, type(r) AS Predicate, b.name AS Object, r.source AS Source, r.evidence AS Evidence\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "##CBM or Sherpa triples\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "MATCH (a)-[r]->(b)\r\n",
    "WHERE r.filePath CONTAINS 'CBM'\r\n",
    "RETURN a.name AS Subject, type(r) AS Predicate, b.name AS Object, r.filePath AS FilePath, r.evidence AS Evidence\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "#get triples by frequency\r\n",
    "\"\"\"\r\n",
    "MATCH (a)-[r]->(b) where b.name is not NULL \r\n",
    "RETURN a.name AS Subject, type(r) AS Predicate, b.name AS Object, COUNT(*) AS Frequency\r\n",
    "ORDER BY Frequency DESC\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "# common nodes between KEGG and Sherpa\r\n",
    "\"\"\"MATCH (n1)-[r1]->(m1), (n2)-[r2]->(m2)\r\n",
    "WHERE apoc.text.distance(n1.name, n2.name) < 7\r\n",
    "  AND r1.source = 'KEGG'\r\n",
    "  AND \"sherpa\" in r2.annotationDatasource \r\n",
    "RETURN DISTINCT n1.name AS Common_Node_KEGG, n2.name AS Common_Node_Sherpa\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6ca1284c7bd7ae5870c8ab738ede617c834b0c6d27e733d7d2a522b2e1e0f98"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.12.0 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}